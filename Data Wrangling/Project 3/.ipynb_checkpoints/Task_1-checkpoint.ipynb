{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Reconstruct the Original Meeting Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Student Name: Siyang Feng\n",
    "#### Student ID: 28246993\n",
    "\n",
    "Date: 04/06/2018\n",
    "\n",
    "Version: 2.0\n",
    "\n",
    "Environment: Python 3.6.2 and Anaconda 4.3.29\n",
    "\n",
    "Libraries used:\n",
    "\n",
    "* re 2.2.1 (for regular express, included in Anaconda Python 3.6)\n",
    "* os (for getting files in directory, included in Anaconda Python 3.6)\n",
    "* BeautifulSoup (for tree structure of xml file, include in Anaconda Python 3.6)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "**Reconstruct meeting transcripts with topical boundaries.** The original meeting transcripts are stored in three different types of XML files, which are ending with \".words.xml\", \".topic.xml\" and \".segments.xml\". (The details about the three types of files can be found in Section 3 below). The task here is to reconstruct the original meeting transcripts with the corresponding topical and paragraph boundaries from these files. \n",
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import XML data and Process\n",
    "* Import all words XML files\n",
    "* Import all segments XML files\n",
    "* Import topic XML file one by one and processing\n",
    "\n",
    "Next step is using variables to record file pathes of segment, word and topic xml file and the path of result text file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get xml directory path\n",
    "seg_xml = \"./segments\"\n",
    "word_xml = \"./words\"\n",
    "topic_xml = \"./topics\"\n",
    "# get text directory path\n",
    "txt_path = './txt_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Generate hash table of words and segments\n",
    "The two functions are defined to parsing one word.XML file or one segment.XML file. \n",
    "\n",
    "Use for loop to traverse all the file and parse all of them into defined data format (hash table):\n",
    "* words: {dict of each file name : {dict of each words #id : (each word, 0)}}\n",
    "* segments: modify words hash table to record segment points\n",
    "    - {dict of each file name : {dict of each words #id : (each word, 1)}}\n",
    "   \n",
    "Regular expression is used to get ID number of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word id number pattern\n",
    "wid_pattern = r'words(\\d+)'\n",
    "w_id = re.compile(wid_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`re.complie` function is used to create regular expression ID selection pattern `w_id` and this pattern will be used to select words ID number further.\n",
    "\n",
    "Function `parsing_one_word` is generated to parse one word xml file into a dictioary. In the dictionary, we select the number of word ID as key and the word as one part of the values. The words dictionary value is a tuple which the first item records the word and the second item record if the word is a segment point mark the second item of tuple as '1' and other will be marked as '0'.\n",
    "\n",
    "Thus, in the `parsing_one_word` function, we don't know which one is segment point. So, we mark all the second item in tuple as '0'. Notice that, this function only record the item with <w ...> in xml file, no `<gap ...>`, `<vocalsound ...>` or other non-words items.\n",
    "    \n",
    "Function `parsing_one_segment` is generated to parse one segment xml file in segment filder. In one segment file, a segment range is recorded as:\n",
    "``` xml\n",
    "<segment nite:id=\"ES2002a.sync.288\" transcriber_end=\"88.982\" transcriber_start=\"85.509\" channel=\"2\">\n",
    "\n",
    "    <nite:child href=\"ES2002a.C.words.xml#id(ES2002a.C.words0)..id(ES2002a.C.words7)\"/>\n",
    "\n",
    "</segment>\n",
    "```\n",
    "We only need the inside tag `<nite:child ...>`\n",
    "```xml \n",
    "    <nite:child href=\"ES2002a.C.words.xml#id(ES2002a.C.words0)..id(ES2002a.C.words7)\"/>\n",
    "```\n",
    "Regular exression is used to select the word xml file infomation such as `ES2002a.C.words.xml`. And we find that the segement range record the start and end word point of the segment range. To easily record the segment, we only need to record the end word point of the segment into the word dictionary by changing the second item of values in word dictionary into '1'.\n",
    "\n",
    "Notice that, the there are some segment point are not marked with word. There may be 'vocalsound' or others. All of all the non-word is not stored into the original dictionary. But because it is still the segment point, thus, we still need it. To solve this problem, we add the non-word segment into word dictionaty with its key ID number and the value of `('', 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_one_word(t):\n",
    "    \"\"\"\n",
    "    parsing a single word xml file and select id and text part to generate a dictionary.\n",
    "    0 in words dict represent segment point, 0 -> no, 1 -> yes.\n",
    "    In this function, imagine no segment point, the value in tuple is all 0.\n",
    "    \n",
    "    Arguements:\n",
    "    t -- word file path\n",
    "    \n",
    "    Return:\n",
    "    words -- a dict of words {'int(id)': ('word', 0)}\n",
    "    \"\"\"\n",
    "    xml_soup = bsoup(open(t), 'lxml')\n",
    "    words = dict()\n",
    "    ws = xml_soup.find_all('w')\n",
    "    for i in ws:\n",
    "        key = w_id.search(i['nite:id']).group(1)\n",
    "        words[int(key)] = (i.get_text(), 0)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_one_segment(t, word_dict):\n",
    "    \"\"\"\n",
    "    parsing a single segment xml file and select contains in 'nite:child'.\n",
    "    label segment points in words dictionary with tag 1.\n",
    "    such as (word, 1)\n",
    "    \n",
    "    Arguements:\n",
    "    t -- segment file path\n",
    "    word_dict -- the created words dictionary \n",
    "    \n",
    "    Return:\n",
    "    word_dict -- relabeled segments word dictionary\n",
    "    \"\"\"\n",
    "    xml_soup = bsoup(open(t), 'lxml')\n",
    "    #segment_ls = list()\n",
    "    segments = xml_soup.find_all('nite:child', href = True)\n",
    "    word_file = re.search(r'^(.+)#', segments[0]['href']).group(1)\n",
    "    for i in segments:\n",
    "        seg_point = re.findall(r'id\\((.+?)\\)',i['href'])[-1]\n",
    "        seg_key = int(w_id.search(seg_point).group(1))\n",
    "        try:\n",
    "            word_dict[word_file][seg_key] = (word_dict[word_file][seg_key][0], 1)\n",
    "        except:  # if segment point in vocalsound label, define previous w label as seg_point\n",
    "            word_dict[word_file][seg_key] = ('', 1)\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions of parsing each words file and parsing each segment file are created.\n",
    "\n",
    "The next step is to generate a hash table of words and then, mark the word with segment tag of 1.\n",
    "\n",
    "In this part, we read all the word and segment xml files into memory. The first function is used to generate original word dictionary (word hash table) with the structure of `{dict of each file name : {dict of each words id : (each word, 0)}}`. To increase the search speed, the outside key is the word file name without '.xml' and the inside key will be the word id number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all words.xml into a dictionary\n",
    "# {dict of each file name : {dict of each words id : (each word, 0)}}\n",
    "words_dict = dict()\n",
    "for wfile in os.listdir(word_xml):\n",
    "    wfile_path = os.path.join(word_xml, wfile)\n",
    "    if os.path.isfile(wfile_path) and wfile_path.endswith('.xml'):\n",
    "        words_dict[wfile] = parsing_one_word(wfile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to mark the segment words in word hash table with changing second item of each value from 0 to 1. In this function all the segment xml file are readed to modify the word hash table by using the modify function `parsing_one_segment`. The final word hash table will be like:\n",
    "``` json\n",
    "{\n",
    "    'ES2002a.A.words.xml': \n",
    "    {\n",
    "        0: ('Hi', 0),\n",
    "        1: (',', 0),\n",
    "        2: (\"I'm\", 0),\n",
    "        3: ('David', 0),\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all segments.xml into the words dictionary : words_dict\n",
    "for sfile in os.listdir(seg_xml):\n",
    "    sfile_path = os.path.join(seg_xml, sfile)\n",
    "    if os.path.isfile(sfile_path) and sfile_path.endswith('.xml'):\n",
    "        words_dict = parsing_one_segment(sfile_path, words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing topic.xml files\n",
    "In this task, the word hash table has been generated before, it should be used to seach the word to generate the final text file. Regard of the requirements, each topic xml file will generate corresponding text file with the same name but end with '.txt'. Thus, in this part, after we parsing each file the result will be wrote into the corresponding text file. Then, parse another topic xml file.\n",
    "* Define functions of parsing topic.xml files.\n",
    "    - parsing each topic in a topic file\n",
    "    - parsing each topic file\n",
    "* Each topic file is parsed through its topics tag. \n",
    "* Each topic is seperated by 10 asterisks.\n",
    "\n",
    "Function `parse_one_topic` is used to parse each topic in a topic xml file. Each topic in a topic file contains multiple paragraphs\n",
    "``` xml\n",
    "    [<nite:child href=\"ES2002a.D.words.xml#id(ES2002a.D.words570)..id(ES2002a.D.words624)\"></nite:child>, ... ]\n",
    "```\n",
    "We should extract the contains of `href` in each tag of `<nite:child >` in each topic. The contains record the word file name and its start word ID and end word ID. All this information were extracted through regular expression. Then, use the word file name and ID to search the word in word hash table to genegrate topic string. Each topic will be ended with 10 asterisks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_topic(a_topic):\n",
    "    \"\"\"\n",
    "    parse all the words in one of the topics in a topic file into a string.\n",
    "    each topic end with '**********'.\n",
    "    \n",
    "    Arguments:\n",
    "    a_topic -- a list of 'nite:child' items contains under a 'topic' tag in a topic file\n",
    "            eg. [<nite:child href=\"ES2002a.D.words.xml#id(ES2002a.D.words570)..id(ES2002a.D.words624)\"></nite:child>, ... ]\n",
    "    \n",
    "    Return:\n",
    "    txt -- a string of all words under the topic \n",
    "    \"\"\"\n",
    "    txt = ''\n",
    "    for ln in a_topic:   # loop 'nite:child' lines in a topic\n",
    "        key = re.search(r'^(.+)#', ln['href']).group(1)  # key of words dict\n",
    "        values = re.findall(r'id\\((.+?)\\)', ln['href'])  # get start and end point in each word part\n",
    "        if len(values) == 2:  # values contains 2 id: is a range\n",
    "            start_num = int(w_id.search(values[0]).group(1))  # get start number dict key\n",
    "            end_num = int(w_id.search(values[1]).group(1))  # get end number dict key\n",
    "            for i in range(start_num, end_num+1): \n",
    "                try:\n",
    "                    if words_dict[key][i][0] == '' and txt[-1] == '\\n':  # all the recorded not word id is marked with segment point 1\n",
    "                        continue\n",
    "                    elif words_dict[key][i][0] == '':\n",
    "                        txt = txt + '\\n'              \n",
    "                    else:  # word part\n",
    "                        txt = txt + ' ' + words_dict[key][i][0]\n",
    "                        if words_dict[key][i][1] == 1:   # the word is marked with segment tag\n",
    "                            txt = txt + '\\n'                \n",
    "                except:  # not segment not word -> not in dict\n",
    "                    continue\n",
    "        else:  # values only contains one id: a word or segment point but not word\n",
    "            st_en_num = int(w_id.search(values[0]).group(1))\n",
    "            try:\n",
    "                if words_dict[key][st_en_num][0] == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    txt = txt + ' ' + words_dict[key][st_en_num][0] + '\\n'\n",
    "            except:  # not segment and not word -> not in dict\n",
    "                continue\n",
    "        # if a line in topic txt is not end with '\\n' add '\\n' \n",
    "        try:\n",
    "            if txt[-1] != '\\n':\n",
    "                txt = txt + '\\n'\n",
    "        except: # the text contains no words\n",
    "            continue\n",
    "    # add ten '*' under the total txt topic \n",
    "    txt = txt + \"*\"*10 + '\\n'   \n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A topic file is consisted of multiple topics. The function `parse_topic_file` is gererated to parse a total topic file. In this function, the function of `parse_one_topic` will be used to parse each topic. The `parse_topic_file` function will loop all the topic in a topic xml file and parse each topic into a string and return the final string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_topic_file(file_path):\n",
    "    \"\"\"\n",
    "    parse a topic file into a string.\n",
    "    use function 'parse_one_topic()' to parse every topic in the topic file\n",
    "    \n",
    "    Arguments:\n",
    "    file_path -- path of a topic file. eg. \"./topics/ES2002a.topic.xml\"\n",
    "    \n",
    "    Return:\n",
    "    txt -- a tring of all words in the topic file\n",
    "    \"\"\"\n",
    "    xml_soup = bsoup(open(file_path), 'lxml')\n",
    "    topics = xml_soup.html.body.next.find_all('topic', recursive=False)\n",
    "    txt = ''\n",
    "    for i in topics:\n",
    "        words_field = i.find_all('nite:child', href=True)  \n",
    "        txt = txt + parse_one_topic(words_field)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Write string into text file\n",
    "Each file will be parsed into a tring, the next step is to write the string into a text file. The function `output_text` do this task with the two parameters: the text string and the destination stored file name and its path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_text(string, file_path):\n",
    "    \"\"\"\n",
    "    Write the string into a text file with defined path.\n",
    "    \n",
    "    Arguments:\n",
    "    string -- input string which need to be write into text file\n",
    "    file_path -- the path of the text to write\n",
    "    \n",
    "    Return:\n",
    "    None\n",
    "    \"\"\"\n",
    "    text_file = open(file_path, 'w')\n",
    "    text_file.write(string)\n",
    "    text_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Retrieval all the topic.xml files in pre-defined directory `txt_path`.\n",
    "* Parse each topic.xml file into a string variable with the previous function: `parse_topic_file`.\n",
    "* Write parsed string into a text file with function `output_text`.\n",
    "* Destination file name is extracted by regular expression to extract from corresponding topic xml file and add `.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tfile in os.listdir(topic_xml):\n",
    "    tfile_path = os.path.join(topic_xml, tfile)\n",
    "    if os.path.isfile(tfile_path) and tfile_path.endswith('.xml'):\n",
    "        txt = parse_topic_file(tfile_path)\n",
    "        txt_file = re.search(r'(.+?)\\.topic', tfile).group(1) + '.txt'  # generate text file name\n",
    "        tx_path = os.path.join(txt_path, txt_file)  # generate a text file path to write in\n",
    "        output_text(txt, tx_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "* In total, we can make words file and segement file together as a hash table and then, word in topic will be searched through its ID in generated hash table and get the final result.\n",
    "* We only select the topics of the first level of the topic file and the inside topic tag will not be considered. Inside each topic, we only need to select the contains of tag `<nite:child >`. To select the first level topic contians:\n",
    "    ``` python\n",
    "        xml_soup.html.body.next.find_all('topic', recursive=False)\n",
    "    ```\n",
    "    This function defines the recursive is False which means there is no recursive. `xml_soup` is the xml file readed by beautifulsoup. This function only select the contains in first level topic tag.\n",
    "* We should conform that a paragraph is defined by the segments and each `<nite:child >` in each topic file. Then, comform that there is only one `\\n` between two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
